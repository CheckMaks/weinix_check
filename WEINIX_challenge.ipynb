{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import csv\n",
    "\n",
    "from pyspark import SparkContext\n",
    "from functools import reduce\n",
    "import re\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.read.csv(\"/Users/maksim/Downloads/wechat_data_medium/weixin_biz\", sep='\\t', header=False).write.saveAsTable('weixin_biz', mode='overwrite')\n",
    "spark.read.csv(\"/Users/maksim/Downloads/wechat_data_medium/weixin_click\", sep='\\t', header=False).write.saveAsTable('weixin_click', mode='overwrite')\n",
    "spark.sparkContext.setCheckpointDir(\"/Users/maksim/Downloads/wechat_data_medium/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_weixin_biz = spark.read.table('weixin_biz')\n",
    "total_weixin_click = spark.read.table('weixin_click')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- _c1: string (nullable = true)\n",
      " |-- _c2: string (nullable = true)\n",
      " |-- _c3: string (nullable = true)\n",
      " |-- _c4: string (nullable = true)\n",
      " |-- _c5: string (nullable = true)\n",
      " |-- _c6: string (nullable = true)\n",
      " |-- _c7: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- _c1: string (nullable = true)\n",
      " |-- _c2: string (nullable = true)\n",
      " |-- _c3: string (nullable = true)\n",
      " |-- _c4: string (nullable = true)\n",
      " |-- _c5: string (nullable = true)\n",
      " |-- _c6: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "total_weixin_biz.printSchema()\n",
    "total_weixin_click.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- _c1: string (nullable = true)\n",
      " |-- _c2: string (nullable = true)\n",
      " |-- _c3: string (nullable = true)\n",
      " |-- _c4: string (nullable = true)\n",
      " |-- _c5: string (nullable = true)\n",
      " |-- _c7: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- _c1: string (nullable = true)\n",
      " |-- _c2: string (nullable = true)\n",
      " |-- _c3: string (nullable = true)\n",
      " |-- _c4: string (nullable = true)\n",
      " |-- _c6: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "total_weixin_biz = total_weixin_biz.drop(\"_c6\") #nothing about this field in task(email)\n",
    "total_weixin_click = total_weixin_click.drop(\"_c5\") #nothing about this field in task(email)\n",
    "\n",
    "total_weixin_biz.printSchema()\n",
    "total_weixin_click.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ID: string (nullable = true)\n",
      " |-- Biz ID: string (nullable = true)\n",
      " |-- Biz Name: string (nullable = true)\n",
      " |-- Biz Code: string (nullable = true)\n",
      " |-- Biz Description: string (nullable = true)\n",
      " |-- QRcode: string (nullable = true)\n",
      " |-- Timestamp: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "old_Names_biz = total_weixin_biz.schema.names\n",
    "new_Names_biz = [\"ID\", \"Biz ID\", \"Biz Name\", \"Biz Code\", \"Biz Description\", \"QRcode\", \"Timestamp\"]\n",
    "\n",
    "df_biz = reduce(lambda total_weixin_biz, idx: total_weixin_biz.withColumnRenamed(old_Names_biz[idx], new_Names_biz[idx]), range(len(old_Names_biz)), total_weixin_biz)\n",
    "df_biz.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['_c0', '_c1', '_c2', '_c3', '_c4', '_c6']\n",
      "root\n",
      " |-- ID: string (nullable = true)\n",
      " |-- URL: string (nullable = true)\n",
      " |-- Title: string (nullable = true)\n",
      " |-- Read Number: string (nullable = true)\n",
      " |-- Like Number: string (nullable = true)\n",
      " |-- Timestamp: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "old_Names_click = total_weixin_click.schema.names\n",
    "print(old_Names_click)\n",
    "new_Names_click = [\"ID\", \"URL\", \"Title\", \"Read Number\", \"Like Number\", \"Timestamp\"]\n",
    "\n",
    "df_click = reduce(lambda total_weixin_click, idx: total_weixin_click.withColumnRenamed(old_Names_click[idx], new_Names_click[idx]), range(len(old_Names_click)), total_weixin_click)\n",
    "df_click.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "257749"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop duplicate according to task\n",
    "clean_weixin_click = df_click.orderBy(\"ID\", \"URL\", \"Title\", col(\"Read Number\").desc(), \"Like Number\", \"Timestamp\") \\\n",
    "                    .dropDuplicates([\"URL\"])\n",
    "c_w_c = clean_weixin_click.withColumn(\"Biz ID\", regexp_extract(\"URL\", '_biz=(.*?)&', 0)) \\\n",
    "                        .select(\"ID\", \"URL\", \"Title\", \"Read Number\", \"Like Number\", \"Timestamp\", regexp_replace('Biz ID', '_biz=', '').alias('Biz ID')).cache() \\\n",
    "                        .select(\"ID\", \"URL\", \"Title\", \"Read Number\", \"Like Number\", \"Timestamp\", regexp_replace('Biz ID', '&', '').alias('Biz ID')).cache()           \n",
    "c_w_c.cache()\n",
    "c_w_c.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2559805\n"
     ]
    }
   ],
   "source": [
    "#I found some duplicate records\n",
    "clean_weixin_biz = df_biz.dropDuplicates([\"ID\", \"Biz ID\"])\n",
    "clean_weixin_biz.cache()\n",
    "\n",
    "print(clean_weixin_biz.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+--------------------+--------------------+-------------------+----------+\n",
      "|          Biz ID|                 Url|               Title|       Publish Date| Timestamp|\n",
      "+----------------+--------------------+--------------------+-------------------+----------+\n",
      "|MzAwOTI5NjczNA==|http://mp.weixin....|【成都精锐教育推荐】2016寒假颁...|2016-01-30 17:35:43|2016-01-31|\n",
      "|MzA5NTcyNzk2NA==|http://mp.weixin....|茂名大道电白段坑漕路面昨天报道后市...|2016-01-30 16:48:34|2016-01-31|\n",
      "|MzA3NDU1MTYwNg==|http://mp.weixin....|   为生孩子问题，婆媳姑嫂大战火力全开|2016-01-30 16:50:30|2016-01-31|\n",
      "|MzA5OTI2NjAyMA==|http://mp.weixin....|有白发的朋友快收藏啊！白发不见皮肤...|2016-01-30 17:18:06|2016-01-31|\n",
      "|MzA3NTQ2MDAyNA==|http://mp.weixin....|  夫妻生活常做这些危害很大，赶紧戒了吧|2016-01-30 15:27:56|2016-01-31|\n",
      "|MzAwNDcwMzY1MA==|http://mp.weixin....|             因为我十分爱你|2016-01-30 11:40:27|2016-01-31|\n",
      "|MjM5NjkyNzM2MQ==|http://mp.weixin....|【单身交友】香港的味道，藏在每条大...|2016-01-30 17:21:49|2016-01-31|\n",
      "|MzA4ODI4NTY4MA==|http://mp.weixin....|★下午刚发生，10000年难遇一次...|2016-01-30 14:34:59|2016-01-31|\n",
      "|MzA4ODkzODIwOA==|http://mp.weixin....|插播一条消息：第二期“星”拍全家福...|2016-01-30 17:09:10|2016-01-31|\n",
      "|MzA5NTI1NjAzMw==|http://mp.weixin....|【来讲讲身边肯对自己下狠手拼了命努...|2016-01-30 17:13:00|2016-01-31|\n",
      "+----------------+--------------------+--------------------+-------------------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[Biz ID: string, Url: string, Title: string, Publish Date: string, Timestamp: string]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logFile = \"/Users/maksim/Downloads/wechat_data_medium/weixin_page_test\"  \n",
    "logData = spark.read.text(logFile).cache()\n",
    "\n",
    "biz_num = logData.withColumn(\"biz\", regexp_extract(\"value\", 'var biz = \"(.*?)\"', 0)) \\\n",
    "                .filter(\"biz != ''\") \\\n",
    "                .select(regexp_extract('biz', r'\"([^\"]*)\"', 0).alias(\"Biz ID\")) \\\n",
    "                .select(regexp_replace('Biz ID', '\"', '').alias('Biz ID')) \n",
    "\n",
    "                \n",
    "url = logData.withColumn(\"url\", regexp_extract(\"value\", '<URL>(.*?)</URL>', 0)) \\\n",
    "                .filter(\"url != ''\") \\\n",
    "                .select(regexp_replace('url', '<(.*?)>', '').alias('Url'))\n",
    "\n",
    "\n",
    "title = logData.withColumn(\"title\", regexp_extract(\"value\", '<TITLE>(.*?)</TITLE>', 0)) \\\n",
    "                .filter(\"title != ''\") \\\n",
    "                .select(regexp_replace('title', '<(.*?)>', '').alias('Title'))\n",
    "\n",
    "            \n",
    "conv_date = udf(lambda x: datetime.fromtimestamp(x).strftime('%Y-%m-%d %H:%M:%S'))     \n",
    "\n",
    "ct = logData.withColumn(\"ct\", regexp_extract(\"value\", 'var ct = \"(.*?)\"', 0)) \\\n",
    "                .filter(\"ct != ''\") \\\n",
    "                .select(regexp_extract('ct', r'\"([^\"]*)\"', 0).alias(\"ct\")) \\\n",
    "                .select(regexp_replace('ct', '\"', '').alias('Publish Date').cast(IntegerType())) \\\n",
    "                .select(conv_date('Publish Date').alias(\"Publish Date\"))\n",
    "\n",
    "date2 = logData.withColumn(\"Timestamp\", regexp_extract(\"value\", '<DATE>(.*?)</DATE>', 0)) \\\n",
    "                .filter(\"Timestamp != ''\") \\\n",
    "                .select(regexp_replace('Timestamp', '<(.*?)>', '').alias('Timestamp'))\n",
    "\n",
    "  \n",
    "    \n",
    "#content = logData.withColumn(\"content\", regexp_extract(\"value\", '<HTML>(.*?)</HTML>', 0)) \\\n",
    "#                 .select(regexp_replace('content', '<(.*?)>', '').alias('content'))\n",
    "#content.take(5)\n",
    "\n",
    "# .filter(\"content != ''\") \\\n",
    "\n",
    "def with_column_index(sdf): \n",
    "    new_schema = StructType(sdf.schema.fields + [StructField(\"ColumnIndex\", LongType(), False),])\n",
    "    return sdf.rdd.zipWithIndex().map(lambda row: row[0] + (row[1],)).toDF(schema=new_schema)\n",
    "\n",
    "df_biz_num = with_column_index(biz_num)\n",
    "df_url = with_column_index(url)\n",
    "df_title = with_column_index(title)\n",
    "df_ct = with_column_index(ct)\n",
    "df_date2 = with_column_index(date2)\n",
    "\n",
    "join_on_index = df_biz_num.join(df_url, [\"ColumnIndex\"]).join(df_title, [\"ColumnIndex\"]).join(df_ct, [\"ColumnIndex\"]).join(df_date2, [\"ColumnIndex\"]).drop(\"ColumnIndex\")\n",
    "join_on_index.show(10)\n",
    "join_on_index.cache()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Biz ID: string (nullable = true)\n",
      " |-- Url: string (nullable = true)\n",
      " |-- Title: string (nullable = true)\n",
      " |-- Publish Date: string (nullable = true)\n",
      " |-- Timestamp: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "join_on_index.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Article URL: string (nullable = true)\n",
      " |-- Article title: string (nullable = true)\n",
      " |-- Read Number: string (nullable = true)\n",
      " |-- Like Number: string (nullable = true)\n",
      " |-- Biz ID: string (nullable = true)\n",
      " |-- Biz Description: string (nullable = true)\n",
      " |-- Biz Name: string (nullable = true)\n",
      " |-- Publish Date: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "join_final_temp = c_w_c.join(broadcast(join_on_index), [\"Biz ID\"])\n",
    "join_final = join_final_temp.select( \"Biz ID\", join_on_index[\"URL\"].alias(\"Article URL\"), \"Read Number\", \"Like Number\", join_on_index[\"Title\"].alias(\"Article title\"), \"Publish Date\")\n",
    "                            \n",
    "join_final_2_temp = join_final.join(clean_weixin_biz, [\"Biz ID\"])\n",
    "join_final_2 = join_final_2_temp.select(\"Article URL\", \"Article title\", \"Read Number\", \"Like Number\", \"Biz ID\", \"Biz Description\", \"Biz Name\", \"Publish Date\")\n",
    "\n",
    "\n",
    "\n",
    "join_final_2.repartition(1).write.csv(\"/Users/maksim/Downloads/cwc_out.csv\", sep='|', header=True)\n",
    "join_final_2.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
